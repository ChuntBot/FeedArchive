feed,title,long_url,short_url
ArXiv:cs.CR,"A Survey of Agentic AI and Cybersecurity: Challenges, Opportunities and Use-case Prototypes",https://arxiv.org/abs/2601.05293,
ArXiv:cs.CR,Multi-turn Jailbreaking Attack in Multi-Modal Large Language Models,https://arxiv.org/abs/2601.05339,
ArXiv:cs.CR,Knowledge-Driven Multi-Turn Jailbreaking on Large Language Models,https://arxiv.org/abs/2601.05445,
ArXiv:cs.CR,Jailbreaking Large Language Models through Iterative Tool-Disguised Attacks via Reinforcement Learning,https://arxiv.org/abs/2601.05466,
ArXiv:cs.CR,Memory Poisoning Attack and Defense on Memory Based LLM-Agents,https://arxiv.org/abs/2601.05504,
ArXiv:cs.CR,Blockchain Verifiable Proof of Quantum Supremacy as a Trigger for Quantum-Secure Signatures,https://arxiv.org/abs/2601.05534,
ArXiv:cs.CR,HogVul: Black-box Adversarial Code Generation Framework Against LM-based Vulnerability Detectors,https://arxiv.org/abs/2601.05587,
ArXiv:cs.CR,Continual Pretraining on Encrypted Synthetic Data for Privacy-Preserving LLMs,https://arxiv.org/abs/2601.05635,
ArXiv:cs.CR,The Echo Chamber Multi-Turn LLM Jailbreak,https://arxiv.org/abs/2601.05742,
ArXiv:cs.CR,VIGIL: Defending LLM Agents Against Tool Stream Injection via Verify-Before-Commit,https://arxiv.org/abs/2601.05755,
ArXiv:cs.CR,Influence of Parallelism in Vector-Multiplication Units on Correlation Power Analysis,https://arxiv.org/abs/2601.05828,
ArXiv:cs.CR,Secure Change-Point Detection for Time Series under Homomorphic Encryption,https://arxiv.org/abs/2601.05865,
ArXiv:cs.CR,Cybersecurity AI: A Game-Theoretic AI for Guiding Attack and Defense,https://arxiv.org/abs/2601.05887,
ArXiv:cs.CR,Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset,https://arxiv.org/abs/2601.05918,
ArXiv:cs.CR,CyberGFM: Graph Foundation Models for Lateral Movement Detection in Enterprise Networks,https://arxiv.org/abs/2601.05988,
ArXiv:cs.CR,When the Server Steps In: Calibrated Updates for Fair Federated Learning,https://arxiv.org/abs/2601.05352,
ArXiv:cs.CR,"AIBoMGen: Generating an AI Bill of Materials for Secure, Transparent, and Compliant Model Training",https://arxiv.org/abs/2601.05703,
ArXiv:cs.CR,PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility,https://arxiv.org/abs/2601.05739,
ArXiv:cs.CR,StriderSPD: Structure-Guided Joint Representation Learning for Binary Security Patch Detection,https://arxiv.org/abs/2601.05772,
ArXiv:cs.CR,Descriptor: Multi-Regional Cloud Honeypot Dataset (MURHCAD),https://arxiv.org/abs/2601.05813,
ArXiv:cs.CR,Deepfake detectors are DUMB: A benchmark to assess adversarial training robustness under transferability constraints,https://arxiv.org/abs/2601.05986,
