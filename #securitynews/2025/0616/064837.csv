feed,title,long_url,short_url
ArXiv:cs.CR,User Perceptions and Attitudes Toward Untraceability in Messaging Platforms,https://arxiv.org/abs/2506.11212,
ArXiv:cs.CR,Uncovering Reliable Indicators: Improving IoC Extraction from Threat Reports,https://arxiv.org/abs/2506.11325,
ArXiv:cs.CR,Bhatt Conjectures: On Necessary-But-Not-Sufficient Benchmark Tautology for Human Like Reasoning,https://arxiv.org/abs/2506.11423,
ArXiv:cs.CR,GaussMarker: Robust Dual-Domain Watermark for Diffusion Models,https://arxiv.org/abs/2506.11444,
ArXiv:cs.CR,Computational Attestations of Polynomial Integrity Towards Verifiable Machine-Learning,https://arxiv.org/abs/2506.11458,
ArXiv:cs.CR,Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models,https://arxiv.org/abs/2506.11521,
ArXiv:cs.CR,SecONNds: Secure Outsourced Neural Network Inference on ImageNet,https://arxiv.org/abs/2506.11586,
ArXiv:cs.CR,KEENHash: Hashing Programs into Function-Aware Embeddings for Large-Scale Binary Code Similarity Analysis,https://arxiv.org/abs/2506.11612,
ArXiv:cs.CR,FAA Framework: A Large Language Model-Based Approach for Credit Card Fraud Investigations,https://arxiv.org/abs/2506.11635,
ArXiv:cs.CR,DTHA: A Digital Twin-Assisted Handover Authentication Scheme for 5G and Beyond,https://arxiv.org/abs/2506.11669,
ArXiv:cs.CR,LLMs on support of privacy and security of mobile apps: state of the art and research directions,https://arxiv.org/abs/2506.11679,
ArXiv:cs.CR,Differential Privacy in Machine Learning: From Symbolic AI to LLMs,https://arxiv.org/abs/2506.11687,
ArXiv:cs.CR,Today's Cat Is Tomorrow's Dog: Accounting for Time-Based Changes in the Labels of ML Vulnerability Detection Approaches,https://arxiv.org/abs/2506.11939,
ArXiv:cs.CR,Technical Evaluation of a Disruptive Approach in Homomorphic AI,https://arxiv.org/abs/2506.11954,
ArXiv:cs.CR,"CnC-PRAC: Coalesce, not Cache, Per Row Activation Counts for an Efficient in-DRAM Rowhammer Mitigation",https://arxiv.org/abs/2506.11970,
ArXiv:cs.CR,Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox,https://arxiv.org/abs/2506.11022,
ArXiv:cs.CR,The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs,https://arxiv.org/abs/2506.11094,
ArXiv:cs.CR,"Byzantine Outside, Curious Inside: Reconstructing Data Through Malicious Updates",https://arxiv.org/abs/2506.11413,
ArXiv:cs.CR,Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs,https://arxiv.org/abs/2506.11415,
ArXiv:cs.CR,On Differential and Boomerang Properties of a Class of Binomials over Finite Fields of Odd Characteristic,https://arxiv.org/abs/2506.11486,
ArXiv:cs.CR,PermRust: A Token-based Permission System for Rust,https://arxiv.org/abs/2506.11701,
ArXiv:cs.CR,SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks,https://arxiv.org/abs/2506.11791,
