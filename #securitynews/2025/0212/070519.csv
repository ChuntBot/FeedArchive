feed,title,long_url,short_url
ArXiv:cs.CR,Automated Consistency Analysis of LLMs,https://arxiv.org/abs/2502.07036,
ArXiv:cs.CR,Scalable and Ethical Insider Threat Detection through Data Synthesis and Analysis by LLMs,https://arxiv.org/abs/2502.07045,
ArXiv:cs.CR,Large Language Models in Software Security: A Survey of Vulnerability Detection Techniques and Insights,https://arxiv.org/abs/2502.07049,
ArXiv:cs.CR,TOCTOU Resilient Attestation for IoT Networks,https://arxiv.org/abs/2502.07053,
ArXiv:cs.CR,Zero-Knowledge Proof Frameworks: A Survey,https://arxiv.org/abs/2502.07063,
ArXiv:cs.CR,General-Purpose $f$-DP Estimation and Auditing in a Black-Box Setting,https://arxiv.org/abs/2502.07066,
ArXiv:cs.CR,Threat Me Right: A Human HARMS Threat Model for Technical Systems,https://arxiv.org/abs/2502.07116,
ArXiv:cs.CR,SAFE: Self-Supervised Anomaly Detection Framework for Intrusion Detection,https://arxiv.org/abs/2502.07119,
ArXiv:cs.CR,Pseudorandomness Properties of Random Reversible Circuits,https://arxiv.org/abs/2502.07159,
ArXiv:cs.CR,A Study on the Importance of Features in Detecting Advanced Persistent Threats Using Machine Learning,https://arxiv.org/abs/2502.07207,
ArXiv:cs.CR,Revisiting the Auxiliary Data in Backdoor Purification,https://arxiv.org/abs/2502.07231,
ArXiv:cs.CR,VLWE: Variety-based Learning with Errors for Vector Encryption through Algebraic Geometry,https://arxiv.org/abs/2502.07284,
ArXiv:cs.CR,EMERALD: Evidence Management for Continuous Certification as a Service in the Cloud,https://arxiv.org/abs/2502.07330,
ArXiv:cs.CR,Mining Power Destruction Attacks in the Presence of Petty-Compliant Mining Pools,https://arxiv.org/abs/2502.07410,
ArXiv:cs.CR,RoMA: Robust Malware Attribution via Byte-level Adversarial Training with Global Perturbations and Adversarial Consistency Regularization,https://arxiv.org/abs/2502.07492,
ArXiv:cs.CR,Decentralized Entropy-Driven Ransomware Detection Using Autonomous Neural Graph Embeddings,https://arxiv.org/abs/2502.07498,
ArXiv:cs.CR,JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation,https://arxiv.org/abs/2502.07557,
ArXiv:cs.CR,Scalable Fingerprinting of Large Language Models,https://arxiv.org/abs/2502.07760,
ArXiv:cs.CR,DROP: Poison Dilution via Knowledge Distillation for Federated Learning,https://arxiv.org/abs/2502.07011,
ArXiv:cs.CR,Distributed Non-Interactive Zero-Knowledge Proofs,https://arxiv.org/abs/2502.07594,
ArXiv:cs.CR,"Private Low-Rank Approximation for Covariance Matrices, Dyson Brownian Motion, and Eigenvalue-Gap Bounds for Gaussian Perturbations",https://arxiv.org/abs/2502.07657,
ArXiv:cs.CR,Auditing Prompt Caching in Language Model APIs,https://arxiv.org/abs/2502.07776,
ArXiv:cs.CR,FairDP: Certified Fairness with Differential Privacy,https://arxiv.org/abs/2305.16474,
ArXiv:cs.CR,Exploring the Bitcoin Mesoscale,https://arxiv.org/abs/2307.14409,
