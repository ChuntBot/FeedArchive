feed,title,long_url,short_url
ArXiv:cs.CR,FedSelect-ME: A Secure Multi-Edge Federated Learning Framework with Adaptive Client Scoring,https://arxiv.org/abs/2511.01898,
ArXiv:cs.CR,Security Audit of intel ICE Driver for e810 Network Interface Card,https://arxiv.org/abs/2511.01910,
ArXiv:cs.CR,Black-Box Membership Inference Attack for LVLMs via Prior Knowledge-Calibrated Memory Probing,https://arxiv.org/abs/2511.01952,
ArXiv:cs.CR,Private Map-Secure Reduce: Infrastructure for Efficient AI Data Markets,https://arxiv.org/abs/2511.02055,
ArXiv:cs.CR,Watermarking Discrete Diffusion Language Models,https://arxiv.org/abs/2511.02083,
ArXiv:cs.CR,The SDSC Satellite Reverse Proxy Service for Launching Secure Jupyter Notebooks on High-Performance Computing Systems,https://arxiv.org/abs/2511.02116,
ArXiv:cs.CR,FLAME: Flexible and Lightweight Biometric Authentication Scheme in Malicious Environments,https://arxiv.org/abs/2511.02176,
ArXiv:cs.CR,PrivGNN: High-Performance Secure Inference for Cryptographic Graph Neural Networks,https://arxiv.org/abs/2511.02185,
ArXiv:cs.CR,"An Automated Framework for Strategy Discovery, Retrieval, and Evolution in LLM Jailbreak Attacks",https://arxiv.org/abs/2511.02356,
ArXiv:cs.CR,Enhancing NTRUEncrypt Security Using Markov Chain Monte Carlo Methods: Theory and Practice,https://arxiv.org/abs/2511.02365,
ArXiv:cs.CR,On The Dangers of Poisoned LLMs In Security Automation,https://arxiv.org/abs/2511.02600,
ArXiv:cs.CR,Verifying LLM Inference to Prevent Model Weight Exfiltration,https://arxiv.org/abs/2511.02620,
ArXiv:cs.CR,Bringing Private Reads to Hyperledger Fabric via Private Information Retrieval,https://arxiv.org/abs/2511.02656,
ArXiv:cs.CR,1 PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts,https://arxiv.org/abs/2511.02780,
ArXiv:cs.CR,Detecting Vulnerabilities from Issue Reports for Internet-of-Things,https://arxiv.org/abs/2511.01941,
ArXiv:cs.CR,Quantum-Enhanced Generative Models for Rare Event Prediction,https://arxiv.org/abs/2511.02042,
ArXiv:cs.CR,AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models,https://arxiv.org/abs/2511.02376,
