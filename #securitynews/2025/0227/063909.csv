feed,title,long_url,short_url
ArXiv:cs.CR,Deep Learning-based Dual Watermarking for Image Copyright Protection and Authentication,https://arxiv.org/abs/2502.18501,
ArXiv:cs.CR,TurboFuzzLLM: Turbocharging Mutation-based Fuzzing for Effectively Jailbreaking Large Language Models in Practice,https://arxiv.org/abs/2502.18504,
ArXiv:cs.CR,REFINE: Inversion-Free Backdoor Defense via Model Reprogramming,https://arxiv.org/abs/2502.18508,
ArXiv:cs.CR,Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents,https://arxiv.org/abs/2502.18509,
ArXiv:cs.CR,ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models,https://arxiv.org/abs/2502.18511,
ArXiv:cs.CR,CipherFace: A Fully Homomorphic Encryption-Driven Framework for Secure Cloud-Based Facial Recognition,https://arxiv.org/abs/2502.18514,
ArXiv:cs.CR,A Multi-Agent Framework for Automated Vulnerability Detection and Repair in Solidity and Move Smart Contracts,https://arxiv.org/abs/2502.18515,
ArXiv:cs.CR,RewardDS: Privacy-Preserving Fine-Tuning for Large Language Models via Reward Driven Data Synthesis,https://arxiv.org/abs/2502.18517,
ArXiv:cs.CR,Swallowing the Poison Pills: Insights from Vulnerability Disparity Among LLMs,https://arxiv.org/abs/2502.18518,
ArXiv:cs.CR,Class-Conditional Neural Polarizer: A Lightweight and Effective Backdoor Defense by Purifying Poisoned Features,https://arxiv.org/abs/2502.18520,
ArXiv:cs.CR,GOD model: Privacy Preserved AI School for Personal Assistant,https://arxiv.org/abs/2502.18527,
ArXiv:cs.CR,ARACNE: An LLM-Based Autonomous Shell Pentesting Agent,https://arxiv.org/abs/2502.18528,
ArXiv:cs.CR,A Survey of Zero-Knowledge Proof Based Verifiable Machine Learning,https://arxiv.org/abs/2502.18535,
ArXiv:cs.CR,PII-Bench: Evaluating Query-Aware Privacy Protection Systems,https://arxiv.org/abs/2502.18545,
ArXiv:cs.CR,Steganography Beyond Space-Time With Chain of Multimodal AI Agents,https://arxiv.org/abs/2502.18547,
ArXiv:cs.CR,Toward Breaking Watermarks in Distortion-free Large Language Models,https://arxiv.org/abs/2502.18608,
ArXiv:cs.CR,IID-Based QPP-RNG: A Random Number Generator Utilizing Random Permutation Sorting Driven by System Jitter,https://arxiv.org/abs/2502.18609,
ArXiv:cs.CR,XTS mode revisited: high hopes for key scopes?,https://arxiv.org/abs/2502.18631,
ArXiv:cs.CR,Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code,https://arxiv.org/abs/2502.18851,
ArXiv:cs.CR,Towards Label-Only Membership Inference Attack against Pre-trained Large Language Models,https://arxiv.org/abs/2502.18943,
ArXiv:cs.CR,Switching multiplicative watermark design against covert attacks,https://arxiv.org/abs/2502.18948,
ArXiv:cs.CR,Evaluating Membership Inference Attacks in heterogeneous-data setups,https://arxiv.org/abs/2502.18986,
ArXiv:cs.CR,Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs,https://arxiv.org/abs/2502.19041,
ArXiv:cs.CR,Towards Privacy-Preserving Anomaly-Based Intrusion Detection in Energy Communities,https://arxiv.org/abs/2502.19154,
ArXiv:cs.CR,Poster: Long PHP webshell files detection based on sliding window attention,https://arxiv.org/abs/2502.19257,
ArXiv:cs.CR,SOK: Exploring Hallucinations and Security Risks in AI-Assisted Software Development with Insights for LLM Deployment,https://arxiv.org/abs/2502.18468,
ArXiv:cs.CR,Target Defense with Multiple Defenders and an Agile Attacker via Residual Policy Learning,https://arxiv.org/abs/2502.18549,
ArXiv:cs.CR,Differentially Private Iterative Screening Rules for Linear Regression,https://arxiv.org/abs/2502.18578,
ArXiv:cs.CR,H-FLTN: A Privacy-Preserving Hierarchical Framework for Electric Vehicle Spatio-Temporal Charge Prediction,https://arxiv.org/abs/2502.18697,
ArXiv:cs.CR,Differentially Private Federated Learning With Time-Adaptive Privacy Spending,https://arxiv.org/abs/2502.18706,
ArXiv:cs.CR,Adversarial Universal Stickers: Universal Perturbation Attacks on Traffic Sign using Stickers,https://arxiv.org/abs/2502.18724,
ArXiv:cs.CR,A Sample-Level Evaluation and Generative Framework for Model Inversion Attacks,https://arxiv.org/abs/2502.19070,
ArXiv:cs.CR,XSS Adversarial Attacks Based on Deep Reinforcement Learning: A Replication and Extension Study,https://arxiv.org/abs/2502.19095,
ArXiv:cs.CR,"Shh, don't say that! Domain Certification in LLMs",https://arxiv.org/abs/2502.19320,
ArXiv:cs.CR,Unveiling Wireless Users' Locations via Modulation Classification-based Passive Attack,https://arxiv.org/abs/2502.19341,
