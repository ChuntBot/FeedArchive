feed,title,long_url,short_url
ArXiv:cs.CR,Current injection and voltage insertion attacks against the VMG-KLJN secure key exchanger,https://arxiv.org/abs/2210.05121v1,
ArXiv:cs.CR,Commitments to Quantum States,https://arxiv.org/abs/2210.05138v1,
ArXiv:cs.CR,Abstract interpretation of Michelson smart-contracts,https://arxiv.org/abs/2210.05217v1,
ArXiv:cs.CR,Detecting Hidden Attackers in Photovoltaic Systems Using Machine Learning,https://arxiv.org/abs/2210.05226v1,
ArXiv:cs.CR,Printing variability of copy detection patterns,https://arxiv.org/abs/2210.05343v1,
ArXiv:cs.CR,On the Feasibility of Profiling Electric Vehicles through Charging Data,https://arxiv.org/abs/2210.05433v1,
ArXiv:cs.CR,Medha: Microcoded Hardware Accelerator for computing on Encrypted Data,https://arxiv.org/abs/2210.05476v1,
ArXiv:cs.CR,Comparison of encrypted control approaches and tutorial on dynamic systems using LWE-based homomorphic encryption,https://arxiv.org/abs/2210.05560v1,
ArXiv:cs.CR,What Can the Neural Tangent Kernel Tell Us About Adversarial Robustness?,https://arxiv.org/abs/2210.05577v1,
ArXiv:cs.CR,Beta-CoRM: A Bayesian Approach for $n$-gram Profiles Analysis,https://arxiv.org/abs/2011.11558v2,
ArXiv:cs.CR,Content-Adaptive Pixel Discretization to Improve Model Robustness,https://arxiv.org/abs/2012.01699v4,
ArXiv:cs.CR,Synthesis of Winning Attacks on Communication Protocols using Supervisory Control Theory: Two Case Studies,https://arxiv.org/abs/2102.06028v3,
ArXiv:cs.CR,Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples,https://arxiv.org/abs/2106.09947v3,
ArXiv:cs.CR,Spinning Sequence-to-Sequence Models with Meta-Backdoors,https://arxiv.org/abs/2107.10443v2,
ArXiv:cs.CR,Adversarial Robustness of Deep Neural Networks: A Survey from a Formal Verification Perspective,https://arxiv.org/abs/2206.12227v2,
ArXiv:cs.CR,What Your Firmware Tells You Is Not How You Should Emulate It: A Specification-Guided Approach for Firmware Emulation (Extended Version),https://arxiv.org/abs/2208.07833v3,
ArXiv:cs.CR,Towards Lightweight Black-Box Attacks against Deep Neural Networks,https://arxiv.org/abs/2209.14826v3,
ArXiv:cs.CR,Red-Teaming the Stable Diffusion Safety Filter,https://arxiv.org/abs/2210.04610v2,
