feed,title,long_url,short_url
ArXiv:cs.CR,Transferable Embedding Inversion Attack: Uncovering Privacy Risks in Text Embeddings without Model Queries,https://arxiv.org/abs/2406.10280,
ArXiv:cs.CR,Watermarking Language Models with Error Correcting Codes,https://arxiv.org/abs/2406.10281,
ArXiv:cs.CR,Hardware-based stack buffer overflow attack detection on RISC-V architectures,https://arxiv.org/abs/2406.10282,
ArXiv:cs.CR,"I Don't Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors",https://arxiv.org/abs/2406.10285,
ArXiv:cs.CR,Malicious URL Detection using optimized Hist Gradient Boosting Classifier based on grid search method,https://arxiv.org/abs/2406.10286,
ArXiv:cs.CR,Security Decisions for Cyber-Physical Systems based on Solving Critical Node Problems with Vulnerable Nodes,https://arxiv.org/abs/2406.10287,
ArXiv:cs.CR,Cyberattack Data Analysis in IoT Environments using Big Data,https://arxiv.org/abs/2406.10302,
ArXiv:cs.CR,I Still See You: Why Existing IoT Traffic Reshaping Fails,https://arxiv.org/abs/2406.10358,
ArXiv:cs.CR,Byzantine-Robust Decentralized Federated Learning,https://arxiv.org/abs/2406.10416,
ArXiv:cs.CR,Enhanced Intrusion Detection System for Multiclass Classification in UAV Networks,https://arxiv.org/abs/2406.10417,
ArXiv:cs.CR,E-SAGE: Explainability-based Defense Against Backdoor Attacks on Graph Neural Networks,https://arxiv.org/abs/2406.10655,
ArXiv:cs.CR,Nurgle: Exacerbating Resource Consumption in Blockchain State Storage via MPT Manipulation,https://arxiv.org/abs/2406.10687,
ArXiv:cs.CR,Trading Devil: Robust backdoor attack via Stochastic investment models and Bayesian approach,https://arxiv.org/abs/2406.10719,
ArXiv:cs.CR,NBA: defensive distillation for backdoor removal via neural behavior alignment,https://arxiv.org/abs/2406.10846,
ArXiv:cs.CR,Make Your Home Safe: Time-aware Unsupervised User Behavior Anomaly Detection in Smart Homes via Loss-guided Mask,https://arxiv.org/abs/2406.10928,
ArXiv:cs.CR,Don't Forget Too Much: Towards Machine Unlearning on Feature Level,https://arxiv.org/abs/2406.10951,
ArXiv:cs.CR,Really Unlearned? Verifying Machine Unlearning via Influential Sample Pairs,https://arxiv.org/abs/2406.10953,
ArXiv:cs.CR,Threat Modelling and Risk Analysis for Large Language Model (LLM)-Powered Applications,https://arxiv.org/abs/2406.11007,
ArXiv:cs.CR,MemDPT: Differential Privacy for Memory Efficient Language Models,https://arxiv.org/abs/2406.11087,
ArXiv:cs.CR,DeFiGuard: A Price Manipulation Detection Service in DeFi using Graph Neural Networks,https://arxiv.org/abs/2406.11157,
ArXiv:cs.CR,Self and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment,https://arxiv.org/abs/2406.11285,
ArXiv:cs.CR,Multimodal Security of Iris and Fingerprint with Bloom Filters,https://arxiv.org/abs/2406.11335,
ArXiv:cs.CR,DIDChain: Advancing Supply Chain Data Management with Decentralized Identifiers and Blockchain,https://arxiv.org/abs/2406.11356,
ArXiv:cs.CR,Decentralized Credential Status Management: A Paradigm Shift in Digital Trust,https://arxiv.org/abs/2406.11511,
ArXiv:cs.CR,Obfuscating IoT Device Scanning Activity via Adversarial Example Generation,https://arxiv.org/abs/2406.11515,
ArXiv:cs.CR,Decentralized Credential Verification,https://arxiv.org/abs/2406.11535,
ArXiv:cs.CR,SoK: A Literature and Engineering Review of Regular Expression Denial of Service,https://arxiv.org/abs/2406.11618,
ArXiv:cs.CR,A First Physical-World Trajectory Prediction Attack via LiDAR-induced Deceptions in Autonomous Driving,https://arxiv.org/abs/2406.11707,
ArXiv:cs.CR,Threat analysis and adversarial model for Smart Grids,https://arxiv.org/abs/2406.11716,
ArXiv:cs.CR,Secure Cross-Chain Provenance for Digital Forensics Collaboration,https://arxiv.org/abs/2406.11729,
ArXiv:cs.CR,Beyond Words: On Large Language Models Actionability in Mission-Critical Risk Analysis,https://arxiv.org/abs/2406.10273,
ArXiv:cs.CR,We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs,https://arxiv.org/abs/2406.10279,
ArXiv:cs.CR,Trusting code in the wild: Exploring contributor reputation measures to review dependencies in the Rust ecosystem,https://arxiv.org/abs/2406.10317,
ArXiv:cs.CR,Adaptive Randomized Smoothing: Certifying Multi-Step Defences against Adversarial Examples,https://arxiv.org/abs/2406.10427,
ArXiv:cs.CR,Extending class group action attacks via sesquilinear pairings,https://arxiv.org/abs/2406.10440,
ArXiv:cs.CR,Privacy-Preserving Heterogeneous Federated Learning for Sensitive Healthcare Data,https://arxiv.org/abs/2406.10563,
ArXiv:cs.CR,"Graph Neural Backdoor: Fundamentals, Methodologies, Applications, and Future Directions",https://arxiv.org/abs/2406.10573,
ArXiv:cs.CR,Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models,https://arxiv.org/abs/2406.10630,
ArXiv:cs.CR,"Linkage on Security, Privacy and Fairness in Federated Learning: New Balances and New Perspectives",https://arxiv.org/abs/2406.10884,
ArXiv:cs.CR,Towards Efficient Target-Level Machine Unlearning Based on Essential Graph,https://arxiv.org/abs/2406.10954,
ArXiv:cs.CR,Promoting Data and Model Privacy in Federated Learning through Quantized LoRA,https://arxiv.org/abs/2406.10976,
ArXiv:cs.CR,Unclonable Secret Sharing,https://arxiv.org/abs/2406.11008,
ArXiv:cs.CR,garak: A Framework for Security Probing Large Language Models,https://arxiv.org/abs/2406.11036,
ArXiv:cs.CR,GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory,https://arxiv.org/abs/2406.11149,
ArXiv:cs.CR,Retraining with Predicted Hard Labels Provably Increases Model Accuracy,https://arxiv.org/abs/2406.11206,
ArXiv:cs.CR,Private Approximate Query over Horizontal Data Federation,https://arxiv.org/abs/2406.11421,
ArXiv:cs.CR,FullCert: Deterministic End-to-End Certification for Training and Inference of Neural Networks,https://arxiv.org/abs/2406.11522,
ArXiv:cs.CR,Do Parameters Reveal More than Loss for Membership Inference?,https://arxiv.org/abs/2406.11544,
ArXiv:cs.CR,Making Old Things New: A Unified Algorithm for Differentially Private Clustering,https://arxiv.org/abs/2406.11649,
ArXiv:cs.CR,Knowledge-to-Jailbreak: One Knowledge Point Worth One Attack,https://arxiv.org/abs/2406.11682,
ArXiv:cs.CR,Tabula: Efficiently Computing Nonlinear Activation Functions for Secure Neural Network Inference,https://arxiv.org/abs/2203.02833,
ArXiv:cs.CR,Honesty is the Best Policy: On the Accuracy of Apple Privacy Labels Compared to Apps' Privacy Policies,https://arxiv.org/abs/2306.17063,
ArXiv:cs.CR,MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance,https://arxiv.org/abs/2401.02906,
ArXiv:cs.CR,FedML-HE: An Efficient Homomorphic-Encryption-Based Privacy-Preserving Federated Learning System,https://arxiv.org/abs/2303.10837,
ArXiv:cs.CR,Event-Triggered Islanding in Inverter-Based Grids,https://arxiv.org/abs/2306.15454,
ArXiv:cs.CR,ULDP-FL: Federated Learning with Across Silo User-Level Differential Privacy,https://arxiv.org/abs/2308.12210,
ArXiv:cs.CR,Hijacking Large Language Models via Adversarial In-Context Learning,https://arxiv.org/abs/2311.09948,
ArXiv:cs.CR,Optimal Attack and Defense for Reinforcement Learning,https://arxiv.org/abs/2312.00198,
