feed,title,long_url,short_url
ArXiv:cs.CR,Hacc-Man: An Arcade Game for Jailbreaking LLMs,https://arxiv.org/abs/2405.15902,
ArXiv:cs.CR,Mitigating Backdoor Attack by Injecting Proactive Defensive Backdoor,https://arxiv.org/abs/2405.16112,
ArXiv:cs.CR,"Individual and Contextual Variables of Cyber Security Behaviour -- An empirical analysis of national culture, industry, organisation, and individual variables of (in)secure human behaviour",https://arxiv.org/abs/2405.16215,
ArXiv:cs.CR,SIGNLINE: Digital signature scheme based on linear equations cryptosystem,https://arxiv.org/abs/2405.16227,
ArXiv:cs.CR,FastQuery: Communication-efficient Embedding Table Query for Private LLM Inference,https://arxiv.org/abs/2405.16241,
ArXiv:cs.CR,Threat Analysis of Industrial Internet of Things Devices,https://arxiv.org/abs/2405.16314,
ArXiv:cs.CR,Analyzing the Attack Surface and Threats of Industrial Internet of Things Devices,https://arxiv.org/abs/2405.16318,
ArXiv:cs.CR,Path-wise Vulnerability Mitigation,https://arxiv.org/abs/2405.16372,
ArXiv:cs.CR,"Towards Sustainable IoT: Challenges, Solutions, and Future Directions for Device Longevity",https://arxiv.org/abs/2405.16421,
ArXiv:cs.CR,KiNETGAN: Enabling Distributed Network Intrusion Detection through Knowledge-Infused Synthetic Data Generation,https://arxiv.org/abs/2405.16476,
ArXiv:cs.CR,MinRank Gabidulin encryption scheme on matrix codes,https://arxiv.org/abs/2405.16539,
ArXiv:cs.CR,Bringing UFUs Back into the Air With FUEL: A Framework for Evaluating the Effectiveness of Unrestricted File Upload Vulnerability Scanners,https://arxiv.org/abs/2405.16619,
ArXiv:cs.CR,Predicting Likely-Vulnerable Code Changes: Machine Learning-based Vulnerability Protections for Android Open Source Project,https://arxiv.org/abs/2405.16655,
ArXiv:cs.CR,Visualizing the Shadows: Unveiling Data Poisoning Behaviors in Federated Learning,https://arxiv.org/abs/2405.16707,
ArXiv:cs.CR,Alistair: Efficient On-device Budgeting for Differentially-Private Ad-Measurement Systems,https://arxiv.org/abs/2405.16719,
ArXiv:cs.CR,Oblivious Monitoring for Discrete-Time STL via Fully Homomorphic Encryption,https://arxiv.org/abs/2405.16767,
ArXiv:cs.CR,TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models,https://arxiv.org/abs/2405.16783,
ArXiv:cs.CR,"Sok: Comprehensive Security Overview, Challenges, and Future Directions of Voice-Controlled Systems",https://arxiv.org/abs/2405.17100,
ArXiv:cs.CR,SoK: Leveraging Transformers for Malware Analysis,https://arxiv.org/abs/2405.17190,
ArXiv:cs.CR,LLM-Assisted Static Analysis for Detecting Security Vulnerabilities,https://arxiv.org/abs/2405.17238,
ArXiv:cs.CR,Peer2PIR: Private Queries for IPFS,https://arxiv.org/abs/2405.17307,
ArXiv:cs.CR,Knowledge-Informed Auto-Penetration Testing Based on Reinforcement Learning with Reward Machine,https://arxiv.org/abs/2405.15908,
ArXiv:cs.CR,Scaling up the Banded Matrix Factorization Mechanism for Differentially Private ML,https://arxiv.org/abs/2405.15913,
ArXiv:cs.CR,Robust width: A lightweight and certifiable adversarial defense,https://arxiv.org/abs/2405.15971,
ArXiv:cs.CR,BadGD: A unified data-centric framework to identify gradient descent vulnerabilities,https://arxiv.org/abs/2405.15979,
ArXiv:cs.CR,Certifying Adapters: Enabling and Enhancing the Certification of Classifier Adversarial Robustness,https://arxiv.org/abs/2405.16036,
ArXiv:cs.CR,No Two Devils Alike: Unveiling Distinct Mechanisms of Fine-tuning Attacks,https://arxiv.org/abs/2405.16229,
ArXiv:cs.CR,LDPKiT: Recovering Utility in LDP Schemes by Training with Noise^2,https://arxiv.org/abs/2405.16361,
ArXiv:cs.CR,Automatic Jailbreaking of the Text-to-Image Generative AI Systems,https://arxiv.org/abs/2405.16567,
ArXiv:cs.CR,A Systematic Review of Federated Generative Models,https://arxiv.org/abs/2405.16682,
ArXiv:cs.CR,The second-order zero differential uniformity of the swapped inverse functions over finite fields,https://arxiv.org/abs/2405.16784,
ArXiv:cs.CR,Blind Data Adaptation to tackle Covariate Shift in Operational Steganalysis,https://arxiv.org/abs/2405.16961,
ArXiv:cs.CR,LabObf: A Label Protection Scheme for Vertical Federated Learning Through Label Obfuscation,https://arxiv.org/abs/2405.17042,
ArXiv:cs.CR,EDEFuzz: A Web API Fuzzer for Excessive Data Exposures,https://arxiv.org/abs/2301.09258,
ArXiv:cs.CR,Blockchain-Envisioned UAV-Aided Disaster Relief Networks: Challenges and Solutions,https://arxiv.org/abs/2310.05180,
ArXiv:cs.CR,Fast Summary-based Whole-program Analysis to Identify Unsafe Memory Accesses in Rust,https://arxiv.org/abs/2310.10298,
ArXiv:cs.CR,FLTrojan: Privacy Leakage Attacks against Federated Language Models Through Selective Weight Tampering,https://arxiv.org/abs/2310.16152,
ArXiv:cs.CR,Assessing Prompt Injection Risks in 200+ Custom GPTs,https://arxiv.org/abs/2311.11538,
ArXiv:cs.CR,The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers,https://arxiv.org/abs/2401.01537,
ArXiv:cs.CR,"The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline",https://arxiv.org/abs/2401.04136,
ArXiv:cs.CR,Send Message to the Future? Blockchain-based Time Machines for Decentralized Reveal of Locked Information,https://arxiv.org/abs/2401.05947,
ArXiv:cs.CR,Multiplicative Reweighting for Robust Neural Network Optimization,https://arxiv.org/abs/2102.12192,
ArXiv:cs.CR,CECILIA: Comprehensive Secure Machine Learning Framework,https://arxiv.org/abs/2202.03023,
ArXiv:cs.CR,Local Model Reconstruction Attacks in Federated Learning and their Uses,https://arxiv.org/abs/2210.16205,
ArXiv:cs.CR,Protecting Federated Learning from Extreme Model Poisoning Attacks via Multidimensional Time Series Anomaly Detection,https://arxiv.org/abs/2303.16668,
ArXiv:cs.CR,Continual Release of Differentially Private Synthetic Data from Longitudinal Data Collections,https://arxiv.org/abs/2306.07884,
ArXiv:cs.CR,Federated Learning: A Cutting-Edge Survey of the Latest Advancements and Applications,https://arxiv.org/abs/2310.05269,
ArXiv:cs.CR,Split-and-Denoise: Protect large language model inference with local differential privacy,https://arxiv.org/abs/2310.09130,
ArXiv:cs.CR,Publicly-Detectable Watermarking for Language Models,https://arxiv.org/abs/2310.18491,
ArXiv:cs.CR,Unveiling Vulnerabilities of Contrastive Recommender Systems to Poisoning Attacks,https://arxiv.org/abs/2311.18244,
ArXiv:cs.CR,Estimation of conditional average treatment effects on distributed data: A privacy-preserving approach,https://arxiv.org/abs/2402.02672,
