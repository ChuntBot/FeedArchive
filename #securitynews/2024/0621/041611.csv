feed,title,long_url,short_url
ArXiv:cs.CR,RMF: A Risk Measurement Framework for Machine Learning Models,https://arxiv.org/abs/2406.12929,
ArXiv:cs.CR,Current state of LLM Risks and AI Guardrails,https://arxiv.org/abs/2406.12934,
ArXiv:cs.CR,ChatBug: A Common Vulnerability of Aligned LLMs Induced by Chat Templates,https://arxiv.org/abs/2406.12935,
ArXiv:cs.CR,Security in IS and social engineering -- an overview and state of the art,https://arxiv.org/abs/2406.12938,
ArXiv:cs.CR,AutoFirm: Automatically Identifying Reused Libraries inside IoT Firmware at Large-Scale,https://arxiv.org/abs/2406.12947,
ArXiv:cs.CR,New Reservoir Computing Kernel Based on Chaotic Chua Circuit and Investigating Application to Post-Quantum Cryptography,https://arxiv.org/abs/2406.12948,
ArXiv:cs.CR,As Advertised? Understanding the Impact of Influencer VPN Ads,https://arxiv.org/abs/2406.13017,
ArXiv:cs.CR,DLP: towards active defense against backdoor attacks with decoupled learning process,https://arxiv.org/abs/2406.13098,
ArXiv:cs.CR,GbHammer: Malicious Inter-process Page Sharing by Hammering Global Bits in Page Table Entries,https://arxiv.org/abs/2406.13119,
ArXiv:cs.CR,Transferable Watermarking to Self-supervised Pre-trained Graph Encoders by Trigger Embeddings,https://arxiv.org/abs/2406.13177,
ArXiv:cs.CR,A Federated Learning Approach for Multi-stage Threat Analysis in Advanced Persistent Threat Campaigns,https://arxiv.org/abs/2406.13186,
ArXiv:cs.CR,Privacy-Preserving Logistic Regression Training on Large Datasets,https://arxiv.org/abs/2406.13221,
ArXiv:cs.CR,Smart Contracts in the Real World: A Statistical Exploration of External Data Dependencies,https://arxiv.org/abs/2406.13253,
ArXiv:cs.CR,Applications of Post-quantum Cryptography,https://arxiv.org/abs/2406.13258,
ArXiv:cs.CR,Cyber Protection Applications of Quantum Computing: A Review,https://arxiv.org/abs/2406.13259,
ArXiv:cs.CR,Textual Unlearning Gives a False Sense of Unlearning,https://arxiv.org/abs/2406.13348,
ArXiv:cs.CR,AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents,https://arxiv.org/abs/2406.13352,
ArXiv:cs.CR,Towards Cyber Threat Intelligence for the IoT,https://arxiv.org/abs/2406.13543,
ArXiv:cs.CR,MEV Ecosystem Evolution From Ethereum 1.0,https://arxiv.org/abs/2406.13585,
ArXiv:cs.CR,Defying the Odds: Solana's Unexpected Resilience in Spite of the Security Challenges Faced by Developers,https://arxiv.org/abs/2406.13599,
ArXiv:cs.CR,Benchmarking Unsupervised Online IDS for Masquerade Attacks in CAN,https://arxiv.org/abs/2406.13778,
ArXiv:cs.CR,Advancing Blockchain Scalability: An Introduction to Layer 1 and Layer 2 Solutions,https://arxiv.org/abs/2406.13855,
ArXiv:cs.CR,Privacy-Preserving ECG Data Analysis with Differential Privacy: A Literature Review and A Case Study,https://arxiv.org/abs/2406.13880,
ArXiv:cs.CR,EnTruth: Enhancing the Traceability of Unauthorized Dataset Usage in Text-to-image Diffusion Models with Minimal and Robust Alterations,https://arxiv.org/abs/2406.13933,
ArXiv:cs.CR,A note on cyclic non-MDS matrices,https://arxiv.org/abs/2406.14013,
ArXiv:cs.CR,Leveraging eBPF and AI for Ransomware Nose Out,https://arxiv.org/abs/2406.14020,
ArXiv:cs.CR,SeCTIS: A Framework to Secure CTI Sharing,https://arxiv.org/abs/2406.14102,
ArXiv:cs.CR,Dye4AI: Assuring Data Boundary on Generative AI Services,https://arxiv.org/abs/2406.14114,
ArXiv:cs.CR,On countering adversarial perturbations in graphs using error correcting codes,https://arxiv.org/abs/2406.14245,
ArXiv:cs.CR,The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts,https://arxiv.org/abs/2406.14318,
ArXiv:cs.CR,Data Plagiarism Index: Characterizing the Privacy Risk of Data-Copying in Tabular Generative Models,https://arxiv.org/abs/2406.13012,
ArXiv:cs.CR,NoiSec: Harnessing Noise for Security against Adversarial and Backdoor Attacks,https://arxiv.org/abs/2406.13073,
ArXiv:cs.CR,An Experimental Characterization of Combined RowHammer and RowPress Read Disturbance in Modern DRAM Chips,https://arxiv.org/abs/2406.13080,
ArXiv:cs.CR,Communication-Efficient and Privacy-Preserving Decentralized Meta-Learning,https://arxiv.org/abs/2406.13183,
ArXiv:cs.CR,AGSOA:Graph Neural Network Targeted Attack Based on Average Gradient and Structure Optimization,https://arxiv.org/abs/2406.13228,
ArXiv:cs.CR,PPT-GNN: A Practical Pre-Trained Spatio-Temporal Graph Neural Network for Network Security,https://arxiv.org/abs/2406.13365,
ArXiv:cs.CR,Exploring Multi-view Pixel Contrast for General and Robust Image Forgery Localization,https://arxiv.org/abs/2406.13565,
ArXiv:cs.CR,Bayes' capacity as a measure for reconstruction attacks in federated learning,https://arxiv.org/abs/2406.13569,
ArXiv:cs.CR,Trusted Video Inpainting Localization via Deep Attentive Noise Learning,https://arxiv.org/abs/2406.13576,
ArXiv:cs.CR,Wiretapped Commitment over Binary Channels,https://arxiv.org/abs/2406.13608,
ArXiv:cs.CR,"The Elusive Pursuit of Replicating PATE-GAN: Benchmarking, Auditing, Debugging",https://arxiv.org/abs/2406.13985,
ArXiv:cs.CR,Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning,https://arxiv.org/abs/2406.14217,
ArXiv:cs.CR,Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning,https://arxiv.org/abs/2406.14322,
ArXiv:cs.CR,PostMark: A Robust Blackbox Watermark for Large Language Models,https://arxiv.org/abs/2406.14517,
ArXiv:cs.CR,"""False negative -- that one is going to kill you"": Understanding Industry Perspectives of Static Analysis based Security Testing",https://arxiv.org/abs/2307.16325,
ArXiv:cs.CR,Sync+Sync: A Covert Channel Built on fsync with Storage,https://arxiv.org/abs/2309.07657,
ArXiv:cs.CR,Differentially Private Bias-Term Fine-tuning of Foundation Models,https://arxiv.org/abs/2210.00036,
ArXiv:cs.CR,Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems,https://arxiv.org/abs/2311.03488,
ArXiv:cs.CR,Exploring ChatGPT's Capabilities on Vulnerability Management,https://arxiv.org/abs/2311.06530,
ArXiv:cs.CR,Contractive Systems Improve Graph Neural Networks Against Adversarial Attacks,https://arxiv.org/abs/2311.06942,
ArXiv:cs.CR,RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models,https://arxiv.org/abs/2311.09641,
ArXiv:cs.CR,Confidence Is All You Need for MI Attacks,https://arxiv.org/abs/2311.15373,
