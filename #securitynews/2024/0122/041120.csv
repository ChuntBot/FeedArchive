feed,title,long_url,short_url
ArXiv:cs.CR,Null Space Properties of Neural Networks with Applications to Image Steganography,https://arxiv.org/abs/2401.10262v1,
ArXiv:cs.CR,Tight Group-Level DP Guarantees for DP-SGD with Sampling via Mixture of Gaussians Mechanisms,https://arxiv.org/abs/2401.10294v1,
ArXiv:cs.CR,Hacking Predictors Means Hacking Cars: Using Sensitivity Analysis to Identify Trajectory Prediction Vulnerabilities for Autonomous Driving Security,https://arxiv.org/abs/2401.10313v1,
ArXiv:cs.CR,Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition,https://arxiv.org/abs/2401.10337v1,
ArXiv:cs.CR,"Excuse me, sir? Your language model is leaking (information)",https://arxiv.org/abs/2401.10360v1,
ArXiv:cs.CR,Vulnerabilities of Foundation Model Integrated Federated Learning Under Adversarial Threats,https://arxiv.org/abs/2401.10375v1,
ArXiv:cs.CR,Bypassing a Reactive Jammer via NOMA-Based Transmissions in Critical Missions,https://arxiv.org/abs/2401.10387v1,
ArXiv:cs.CR,Contrastive Unlearning: A Contrastive Approach to Machine Unlearning,https://arxiv.org/abs/2401.10458v1,
ArXiv:cs.CR,Exploiting Kubernetes' Image Pull Implementation to Deny Node Availability,https://arxiv.org/abs/2401.10582v1,
ArXiv:cs.CR,PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks,https://arxiv.org/abs/2401.10586v1,
ArXiv:cs.CR,Adversarially Robust Signed Graph Contrastive Learning from Balance Augmentation,https://arxiv.org/abs/2401.10590v1,
ArXiv:cs.CR,FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks,https://arxiv.org/abs/2401.10657v1,
ArXiv:cs.CR,PTPsec: Securing the Precision Time Protocol Against Time Delay Attacks Using Cyclic Path Asymmetry Analysis,https://arxiv.org/abs/2401.10664v1,
ArXiv:cs.CR,Deep Learning-based Embedded Intrusion Detection System for Automotive CAN,https://arxiv.org/abs/2401.10674v1,
ArXiv:cs.CR,A Lightweight Multi-Attack CAN Intrusion Detection System on Hybrid FPGAs,https://arxiv.org/abs/2401.10689v1,
ArXiv:cs.CR,Explainable and Transferable Adversarial Attack for ML-Based Network Intrusion Detectors,https://arxiv.org/abs/2401.10691v1,
ArXiv:cs.CR,Real-Time Zero-Day Intrusion Detection System for Automotive Controller Area Network on FPGAs,https://arxiv.org/abs/2401.10724v1,
ArXiv:cs.CR,A Survey and Comparative Analysis of Security Properties of CAN Authentication Protocols,https://arxiv.org/abs/2401.10736v1,
ArXiv:cs.CR,Starlit: Privacy-Preserving Federated Learning to Enhance Financial Fraud Detection,https://arxiv.org/abs/2401.10765v1,
ArXiv:cs.CR,Hybrid Online Certificate Status Protocol with Certificate Revocation List for Smart Grid Public Key Infrastructure,https://arxiv.org/abs/2401.10787v1,
ArXiv:cs.CR,Ensembler: Combating model inversion attacks using model ensemble during collaborative inference,https://arxiv.org/abs/2401.10859v1,
ArXiv:cs.CR,Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning,https://arxiv.org/abs/2401.10862v1,
ArXiv:cs.CR,Have it your way: Individualized Privacy Assignment for DP-SGD,https://arxiv.org/abs/2303.17046v2,
ArXiv:cs.CR,SoK: The Ghost Trilemma,https://arxiv.org/abs/2308.02202v3,
ArXiv:cs.CR,Short Paper: Accountable Safety Implies Finality,https://arxiv.org/abs/2308.16902v3,
ArXiv:cs.CR,Privacy-Preserving Neural Graph Databases,https://arxiv.org/abs/2312.15591v2,
ArXiv:cs.CR,Deep Efficient Private Neighbor Generation for Subgraph Federated Learning,https://arxiv.org/abs/2401.04336v3,
ArXiv:cs.CR,Towards Efficient and Certified Recovery from Poisoning Attacks in Federated Learning,https://arxiv.org/abs/2401.08216v2,
ArXiv:cs.CR,Hijacking Attacks against Neural Networks by Analyzing Training Data,https://arxiv.org/abs/2401.09740v2,
ArXiv:cs.CR,"A Fast, Performant, Secure Distributed Training Framework For Large Language Model",https://arxiv.org/abs/2401.09796v2,
ArXiv:cs.CR,Analysis of a Programmable Quantum Annealer as a Random Number Generator,https://arxiv.org/abs/2307.02573v2,
