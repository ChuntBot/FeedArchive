feed,title,long_url,short_url
ArXiv:cs.CR,Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters,https://arxiv.org/abs/2405.20413,
ArXiv:cs.CR,SECURE: Benchmarking Generative Large Language Models for Cybersecurity Advisory,https://arxiv.org/abs/2405.20441,
ArXiv:cs.CR,Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation,https://arxiv.org/abs/2405.20446,
ArXiv:cs.CR,Hiding Your Awful Online Choices Made More Efficient and Secure: A New Privacy-Aware Recommender System,https://arxiv.org/abs/2405.20483,
ArXiv:cs.CR,Phantom: General Trigger Attacks on Retrieval Augmented Language Generation,https://arxiv.org/abs/2405.20485,
ArXiv:cs.CR,SoK: Public Blockchain Sharding,https://arxiv.org/abs/2405.20521,
ArXiv:cs.CR,All Your Tokens are Belong to Us: Demystifying Address Verification Vulnerabilities in Solidity Smart Contracts,https://arxiv.org/abs/2405.20561,
ArXiv:cs.CR,Federated Graph Analytics with Differential Privacy,https://arxiv.org/abs/2405.20576,
ArXiv:cs.CR,Bi-Directional Transformers vs. word2vec: Discovering Vulnerabilities in Lifted Compiled Code,https://arxiv.org/abs/2405.20611,
ArXiv:cs.CR,Query Provenance Analysis for Robust and Efficient Query-based Black-box Attack Defense,https://arxiv.org/abs/2405.20641,
ArXiv:cs.CR,No Free Lunch Theorem for Privacy-Preserving LLM Inference,https://arxiv.org/abs/2405.20681,
ArXiv:cs.CR,A Lightweight Method for Defending Against UAF Vulnerabilities,https://arxiv.org/abs/2405.20697,
ArXiv:cs.CR,Fast Evaluation of S-boxes with Garbled Circuits,https://arxiv.org/abs/2405.20713,
ArXiv:cs.CR,GANcrop: A Contrastive Defense Against Backdoor Attacks in Federated Learning,https://arxiv.org/abs/2405.20727,
ArXiv:cs.CR,Comparison of Access Control Approaches for Graph-Structured Data,https://arxiv.org/abs/2405.20762,
ArXiv:cs.CR,Avoiding Pitfalls for Privacy Accounting of Subsampled Mechanisms under Composition,https://arxiv.org/abs/2405.20769,
ArXiv:cs.CR,Towards Black-Box Membership Inference Attack for Diffusion Models,https://arxiv.org/abs/2405.20771,
ArXiv:cs.CR,Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Characte,https://arxiv.org/abs/2405.20773,
ArXiv:cs.CR,Exploring Backdoor Attacks against Large Language Model-based Decision Making,https://arxiv.org/abs/2405.20774,
ArXiv:cs.CR,Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models,https://arxiv.org/abs/2405.20775,
ArXiv:cs.CR,Federated Learning with Blockchain-Enhanced Machine Unlearning: A Trustworthy Approach,https://arxiv.org/abs/2405.20776,
ArXiv:cs.CR,Black-Box Detection of Language Model Watermarks,https://arxiv.org/abs/2405.20777,
ArXiv:cs.CR,Improved Generation of Adversarial Examples Against Safety-aligned LLMs,https://arxiv.org/abs/2405.20778,
ArXiv:cs.CR,Asymptotic utility of spectral anonymization,https://arxiv.org/abs/2405.20779,
ArXiv:cs.CR,Universal Exact Compression of Differentially Private Mechanisms,https://arxiv.org/abs/2405.20782,
ArXiv:cs.CR,How the Future Works at SOUPS: Analyzing Future Work Statements and Their Impact on Usable Security and Privacy Research,https://arxiv.org/abs/2405.20785,
ArXiv:cs.CR,BackdoorIndicator: Leveraging OOD Data for Proactive Backdoor Detection in Federated Learning,https://arxiv.org/abs/2405.20862,
ArXiv:cs.CR,RASE: Efficient Privacy-preserving Data Aggregation against Disclosure Attacks for IoTs,https://arxiv.org/abs/2405.20914,
ArXiv:cs.CR,A new multivariate primitive from CCZ equivalence,https://arxiv.org/abs/2405.20968,
ArXiv:cs.CR,ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning,https://arxiv.org/abs/2405.20975,
ArXiv:cs.CR,Locking Machine Learning Models into Hardware,https://arxiv.org/abs/2405.20990,
ArXiv:cs.CR,Enhancing Adversarial Robustness in SNNs with Sparse Gradients,https://arxiv.org/abs/2405.20355,
ArXiv:cs.CR,Gradient Inversion of Federated Diffusion Models,https://arxiv.org/abs/2405.20380,
ArXiv:cs.CR,Private Mean Estimation with Person-Level Differential Privacy,https://arxiv.org/abs/2405.20405,
ArXiv:cs.CR,Optimizing cnn-Bigru performance: Mish activation and comparative analysis with Relu,https://arxiv.org/abs/2405.20503,
ArXiv:cs.CR,SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents,https://arxiv.org/abs/2405.20539,
ArXiv:cs.CR,Share Your Secrets for Privacy! Confidential Forecasting with Vertical Federated Learning,https://arxiv.org/abs/2405.20761,
ArXiv:cs.CR,Large Language Model Sentinel: Advancing Adversarial Robustness by LLM Agent,https://arxiv.org/abs/2405.20770,
ArXiv:cs.CR,"Preemptive Answer ""Attacks"" on Chain-of-Thought Reasoning",https://arxiv.org/abs/2405.20902,
ArXiv:cs.CR,Improved Techniques for Optimization-Based Jailbreaking on Large Language Models,https://arxiv.org/abs/2405.21018,
ArXiv:cs.CR,LIA: Privacy-Preserving Data Quality Evaluation in Federated Learning Using a Lazy Influence Approximation,https://arxiv.org/abs/2205.11518,
ArXiv:cs.CR,Digital Inheritance in Web3: A Case Study of Soulbound Tokens and the Social Recovery Pallet within the Polkadot and Kusama Ecosystems,https://arxiv.org/abs/2301.11074,
ArXiv:cs.CR,Differentially Private Data Generation with Missing Data,https://arxiv.org/abs/2310.11548,
ArXiv:cs.CR,The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation,https://arxiv.org/abs/2312.09085,
