feed,title,long_url,short_url
ArXiv:cs.CR,Disrupting Model Training with Adversarial Shortcuts,https://arxiv.org/abs/2106.06654v1,
ArXiv:cs.CR,TDGIA:Effective Injection Attacks on Graph Neural Networks,https://arxiv.org/abs/2106.06663v1,
ArXiv:cs.CR,Towards a Privacy-preserving Deep Learning-based Network Intrusion Detection in Data Distribution Services,https://arxiv.org/abs/2106.06765v1,
ArXiv:cs.CR,FeSHI: Feature Map Based Stealthy Hardware Intrinsic Attack,https://arxiv.org/abs/2106.06895v1,
ArXiv:cs.CR,Expected Tight Bounds for Robust Training,https://arxiv.org/abs/1905.12418v5,
ArXiv:cs.CR,Quantum Indistinguishability for Public Key Encryption,https://arxiv.org/abs/2003.00578v5,
ArXiv:cs.CR,Duplicity Games for Deception Design with an Application to Insider Threat Mitigation,https://arxiv.org/abs/2006.07942v2,
ArXiv:cs.CR,Defending against Backdoors in Federated Learning with Robust Learning Rate,https://arxiv.org/abs/2007.03767v3,
ArXiv:cs.CR,Federated Learning with Sparsification-Amplified Privacy and Adaptive Optimization,https://arxiv.org/abs/2008.01558v2,
ArXiv:cs.CR,Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack,https://arxiv.org/abs/2009.06701v2,
ArXiv:cs.CR,RobustBench: a standardized adversarial robustness benchmark,https://arxiv.org/abs/2010.09670v2,
ArXiv:cs.CR,Budget Sharing for Multi-Analyst Differential Privacy,https://arxiv.org/abs/2011.01192v3,
ArXiv:cs.CR,Extremal Set Theory and LWE Based Access Structure Hiding Verifiable Secret Sharing with Malicious-Majority and Free Verification,https://arxiv.org/abs/2011.14804v3,
ArXiv:cs.CR,A Distributed and Secure Algorithm for Computing Dominant SVD Based on Projection Splitting,https://arxiv.org/abs/2012.03461v3,
ArXiv:cs.CR,Confidential Machine Learning on Untrusted Platforms: A Survey,https://arxiv.org/abs/2012.08156v2,
ArXiv:cs.CR,Towards Certifying L-infinity Robustness using Neural Networks with L-inf-dist Neurons,https://arxiv.org/abs/2102.05363v4,
ArXiv:cs.CR,Globally-Robust Neural Networks,https://arxiv.org/abs/2102.08452v2,
ArXiv:cs.CR,Fortify Machine Learning Production Systems: Detect and Classify Adversarial Attacks,https://arxiv.org/abs/2102.09695v3,
ArXiv:cs.CR,Decoding supercodes of Gabidulin codes and applications to cryptanalysis,https://arxiv.org/abs/2103.02700v2,
ArXiv:cs.CR,On the Impossibility of Post-Quantum Black-Box Zero-Knowledge in Constant Rounds,https://arxiv.org/abs/2103.11244v2,
ArXiv:cs.CR,Private and Resource-Bounded Locally Decodable Codes for Insertions and Deletions,https://arxiv.org/abs/2103.14122v3,
ArXiv:cs.CR,SoK: Design Tools for Side-Channel-Aware Implementations,https://arxiv.org/abs/2104.08593v2,
ArXiv:cs.CR,Hunter in the Dark: Discover Anomalous Network Activity Using Deep Ensemble Network,https://arxiv.org/abs/2105.09157v2,
ArXiv:cs.CR,User Label Leakage from Gradients in Federated Learning,https://arxiv.org/abs/2105.09369v3,
ArXiv:cs.CR,Nori: Concealing the Concealed Identifier in 5G,https://arxiv.org/abs/2105.10440v2,
ArXiv:cs.CR,Precise Approximation of Convolutional Neural Networks for Homomorphically Encrypted Data,https://arxiv.org/abs/2105.10879v4,
ArXiv:cs.CR,"Information Theoretic Evaluation of Privacy-Leakage, Interpretability, and Transferability for a Novel Trustworthy AI Framework",https://arxiv.org/abs/2106.06046v2,
