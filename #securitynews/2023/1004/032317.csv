feed,title,long_url,short_url
ArXiv:cs.CR,Enhancing Secrecy in UAV RSMA Networks: Deep Unfolding Meets Deep Reinforcement Learning,https://arxiv.org/abs/2310.01437v1,
ArXiv:cs.CR,On the Safety of Open-Sourced Large Language Models: Does Alignment Really Prevent Them From Being Misused?,https://arxiv.org/abs/2310.01581v1,
ArXiv:cs.CR,Intractability of Learning the Discrete Logarithm with Gradient-Based Methods,https://arxiv.org/abs/2310.01611v1,
ArXiv:cs.CR,Artemis: HE-Aware Training for Efficient Privacy-Preserving Machine Learning,https://arxiv.org/abs/2310.01664v1,
ArXiv:cs.CR,Decision-Dominant Strategic Defense Against Lateral Movement for 5G Zero-Trust Multi-Domain Networks,https://arxiv.org/abs/2310.01675v1,
ArXiv:cs.CR,Risk and Threat Mitigation Techniques in Internet of Things (IoT) Environments: A Survey,https://arxiv.org/abs/2310.01676v1,
ArXiv:cs.CR,Threat Modelling in Internet of Things (IoT) Environment Using Dynamic Attack Graphs,https://arxiv.org/abs/2310.01689v1,
ArXiv:cs.CR,5G Network Slicing: Analysis of Multiple Machine Learning Classifiers,https://arxiv.org/abs/2310.01747v1,
ArXiv:cs.CR,AutoLoRa: A Parameter-Free Automated Robust Fine-Tuning Framework,https://arxiv.org/abs/2310.01818v1,
ArXiv:cs.CR,Multi-class Network Intrusion Detection with Class Imbalance via LSTM & SMOTE,https://arxiv.org/abs/2310.01850v1,
ArXiv:cs.CR,Towards Stable Backdoor Purification through Feature Shift Tuning,https://arxiv.org/abs/2310.01875v1,
ArXiv:cs.CR,Enhancing Workflow Security in Multi-Cloud Environments through Monitoring and Adaptation upon Cloud Service and Network Security Violations,https://arxiv.org/abs/2310.01878v1,
ArXiv:cs.CR,Waveform Manipulation Against DNN-based Modulation Classification Attacks,https://arxiv.org/abs/2310.01894v1,
ArXiv:cs.CR,Beyond Labeling Oracles: What does it mean to steal ML models?,https://arxiv.org/abs/2310.01959v1,
ArXiv:cs.CR,Steganalysis of AI Models LSB Attacks,https://arxiv.org/abs/2310.01969v1,
ArXiv:cs.CR,Security Weaknesses of Copilot Generated Code in GitHub,https://arxiv.org/abs/2310.02059v1,
ArXiv:cs.CR,Gotta Catch 'em All: Aggregating CVSS Scores,https://arxiv.org/abs/2310.02062v1,
ArXiv:cs.CR,Certifiers Make Neural Networks Vulnerable to Availability Attacks,https://arxiv.org/abs/2108.11299v5,
ArXiv:cs.CR,BliMe: Verifiably Secure Outsourced Computation with Hardware-Enforced Taint Tracking,https://arxiv.org/abs/2204.09649v7,
ArXiv:cs.CR,DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness,https://arxiv.org/abs/2303.13372v3,
ArXiv:cs.CR,"Verifying the First Nonzero Term: Physical ZKPs for ABC End View, Goishi Hiroi, and Toichika",https://arxiv.org/abs/2304.12388v3,
ArXiv:cs.CR,Interactive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning,https://arxiv.org/abs/2304.14540v4,
ArXiv:cs.CR,Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples,https://arxiv.org/abs/2305.09241v5,
ArXiv:cs.CR,Differentially Private Latent Diffusion Models,https://arxiv.org/abs/2305.15759v2,
ArXiv:cs.CR,Transaction Fee Mechanism Design with Active Block Producers,https://arxiv.org/abs/2307.01686v2,
ArXiv:cs.CR,Towards Traitor Tracing in Black-and-White-Box DNN Watermarking with Tardos-based Codes,https://arxiv.org/abs/2307.06695v3,
ArXiv:cs.CR,Abusing Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs,https://arxiv.org/abs/2307.10490v4,
ArXiv:cs.CR,A Brief Yet In-Depth Survey of Deep Learning-Based Image Watermarking,https://arxiv.org/abs/2308.04603v2,
ArXiv:cs.CR,Evaluating Homomorphic Operations on a Real-World Processing-In-Memory System,https://arxiv.org/abs/2309.06545v2,
ArXiv:cs.CR,On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures,https://arxiv.org/abs/2309.12955v2,
ArXiv:cs.CR,How well does LLM generate security tests?,https://arxiv.org/abs/2310.00710v2,
