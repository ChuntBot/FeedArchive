feed,title,long_url,short_url
ArXiv:cs.CR,"Invisible, Unreadable, and Inaudible Cookie Notices: An Evaluation of Cookie Notices for Users with Visual Impairments",https://arxiv.org/abs/2308.11643v1,
ArXiv:cs.CR,Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection,https://arxiv.org/abs/2308.11754v1,
ArXiv:cs.CR,Ceci n'est pas une pomme: Adversarial Illusions in Multi-Modal Embeddings,https://arxiv.org/abs/2308.11804v1,
ArXiv:cs.CR,PatchBackdoor: Backdoor Attack against Deep Neural Networks without Model Modification,https://arxiv.org/abs/2308.11822v1,
ArXiv:cs.CR,Performance Comparison and Implementation of Bayesian Variants for Network Intrusion Detection,https://arxiv.org/abs/2308.11834v1,
ArXiv:cs.CR,A Survey for Federated Learning Evaluations: Goals and Measures,https://arxiv.org/abs/2308.11841v1,
ArXiv:cs.CR,SEA: Shareable and Explainable Attribution for Query-based Black-box Attacks,https://arxiv.org/abs/2308.11845v1,
ArXiv:cs.CR,Empirical Analysis of Software Vulnerabilities Causing Timing Side Channels,https://arxiv.org/abs/2308.11862v1,
ArXiv:cs.CR,Adversarial Training Using Feedback Loops,https://arxiv.org/abs/2308.11881v1,
ArXiv:cs.CR,Does Physical Adversarial Example Really Matter to Autonomous Driving? Towards System-Level Effect of Adversarial Object Evasion Attack,https://arxiv.org/abs/2308.11894v1,
ArXiv:cs.CR,PARseL: Towards a Verified Root-of-Trust over seL4,https://arxiv.org/abs/2308.11921v1,
ArXiv:cs.CR,Bias-Aware Minimisation: Understanding and Mitigating Estimator Bias in Private SGD,https://arxiv.org/abs/2308.12018v1,
ArXiv:cs.CR,Sample Complexity of Robust Learning against Evasion Attacks,https://arxiv.org/abs/2308.12054v1,
ArXiv:cs.CR,Unleashing IoT Security: Assessing the Effectiveness of Best Practices in Protecting Against Threats,https://arxiv.org/abs/2308.12072v1,
ArXiv:cs.CR,Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments,https://arxiv.org/abs/2308.12086v1,
ArXiv:cs.CR,DarkDiff: Explainable web page similarity of TOR onion sites,https://arxiv.org/abs/2308.12134v1,
ArXiv:cs.CR,A Probabilistic Fluctuation based Membership Inference Attack for Generative Models,https://arxiv.org/abs/2308.12143v1,
ArXiv:cs.CR,Unsupervised anomalies detection in IIoT edge devices networks using federated learning,https://arxiv.org/abs/2308.12175v1,
ArXiv:cs.CR,ULDP-FL: Federated Learning with Across Silo User-Level Differential Privacy,https://arxiv.org/abs/2308.12210v1,
ArXiv:cs.CR,Devising and Detecting Phishing: large language models vs. Smaller Human Models,https://arxiv.org/abs/2308.12287v1,
ArXiv:cs.CR,Comprehension from Chaos: Towards Informed Consent for Private Computation,https://arxiv.org/abs/2211.07026v2,
ArXiv:cs.CR,Security Analysis of the Consumer Remote SIM Provisioning Protocol,https://arxiv.org/abs/2211.15323v2,
ArXiv:cs.CR,No Easy Way Out: the Effectiveness of Deplatforming an Extremist Forum to Suppress Hate and Harassment,https://arxiv.org/abs/2304.07037v3,
ArXiv:cs.CR,On the Uses of Large Language Models to Interpret Ambiguous Cyberattack Descriptions,https://arxiv.org/abs/2306.14062v2,
ArXiv:cs.CR,On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey,https://arxiv.org/abs/2307.16680v4,
ArXiv:cs.CR,Understanding Hackers' Work: An Empirical Study of Offensive Security Practitioners,https://arxiv.org/abs/2308.07057v3,
ArXiv:cs.CR,SHAPFUZZ: Efficient Fuzzing via Shapley-Guided Byte Selection,https://arxiv.org/abs/2308.09239v2,
ArXiv:cs.CR,Backdooring Textual Inversion for Concept Censorship,https://arxiv.org/abs/2308.10718v2,
ArXiv:cs.CR,Designing an attack-defense game: how to increase robustness of financial transaction models via a competition,https://arxiv.org/abs/2308.11406v2,
