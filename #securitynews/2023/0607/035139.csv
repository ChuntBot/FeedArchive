feed,title,long_url,short_url
ArXiv:cs.CR,Information Flow Control in Machine Learning through Modular Model Architecture,https://arxiv.org/abs/2306.03235v1,
ArXiv:cs.CR,Generating Private Synthetic Data with Genetic Algorithms,https://arxiv.org/abs/2306.03257v1,
ArXiv:cs.CR,Security Knowledge-Guided Fuzzing of Deep Learning Libraries,https://arxiv.org/abs/2306.03269v1,
ArXiv:cs.CR,Quantum Blockchain Miners Provide Massive Energy Savings,https://arxiv.org/abs/2306.03321v1,
ArXiv:cs.CR,X-ray: Discovering DRAM Internal Structure and Error Characteristics by Issuing Memory Commands,https://arxiv.org/abs/2306.03366v1,
ArXiv:cs.CR,OptimShare: A Unified Framework for Privacy Preserving Data Sharing -- Towards the Practical Utility of Data with Privacy,https://arxiv.org/abs/2306.03379v1,
ArXiv:cs.CR,A Survey on Federated Learning Poisoning Attacks and Defenses,https://arxiv.org/abs/2306.03397v1,
ArXiv:cs.CR,Protecting the Intellectual Property of Diffusion Models by the Watermark Diffusion Process,https://arxiv.org/abs/2306.03436v1,
ArXiv:cs.CR,Correlated Pseudorandomness from the Hardness of Quasi-Abelian Decoding,https://arxiv.org/abs/2306.03488v1,
ArXiv:cs.CR,Adversarial Attacks and Defenses for Semantic Communication in Vehicular Metaverses,https://arxiv.org/abs/2306.03528v1,
ArXiv:cs.CR,Greedy-Mine: A Profitable Mining Attack Strategy in Bitcoin-NG,https://arxiv.org/abs/2306.03540v1,
ArXiv:cs.CR,A Practical Framework for Storing and Searching Encrypted Data on Cloud Storage,https://arxiv.org/abs/2306.03547v1,
ArXiv:cs.CR,Machine Unlearning: A Survey,https://arxiv.org/abs/2306.03558v1,
ArXiv:cs.CR,mdTLS: How to Make middlebox-aware TLS more efficient?,https://arxiv.org/abs/2306.03573v1,
ArXiv:cs.CR,TALUS: Reinforcing TEE Confidentiality with Cryptographic Coprocessors (Technical Report),https://arxiv.org/abs/2306.03643v1,
ArXiv:cs.CR,Deep Serial Number: Computational Watermarking for DNN Intellectual Property Protection,https://arxiv.org/abs/2011.08960v2,
ArXiv:cs.CR,More is Merrier in Collusion Mitigation,https://arxiv.org/abs/2201.07740v4,
ArXiv:cs.CR,I Know What You Trained Last Summer: A Survey on Stealing Machine Learning Models and Defences,https://arxiv.org/abs/2206.08451v2,
ArXiv:cs.CR,Robust Universal Adversarial Perturbations,https://arxiv.org/abs/2206.10858v2,
ArXiv:cs.CR,Lattice-Based Quantum Advantage from Rotated Measurements,https://arxiv.org/abs/2210.10143v2,
ArXiv:cs.CR,Can Querying for Bias Leak Protected Attributes? Achieving Privacy With Smooth Sensitivity,https://arxiv.org/abs/2211.02139v2,
ArXiv:cs.CR,A Watermark for Large Language Models,https://arxiv.org/abs/2301.10226v3,
ArXiv:cs.CR,Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples,https://arxiv.org/abs/2302.04578v2,
ArXiv:cs.CR,DP-BART for Privatized Text Rewriting under Local Differential Privacy,https://arxiv.org/abs/2302.07636v2,
ArXiv:cs.CR,Exploring the Limits of Model-Targeted Indiscriminate Data Poisoning Attacks,https://arxiv.org/abs/2303.03592v3,
ArXiv:cs.CR,Canary in Twitter Mine: Collecting Phishing Reports from Experts and Non-experts,https://arxiv.org/abs/2303.15847v2,
ArXiv:cs.CR,Decentralized Threshold Signatures with Dynamically Private Accountability,https://arxiv.org/abs/2304.07937v4,
ArXiv:cs.CR,Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning,https://arxiv.org/abs/2306.03013v2,
